# -*- coding: utf-8 -*-
"""Another copy of DeepFake_MesoNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gk7t3wPbG09SVNfhzPqfsxr-lsGrRl5s

# Deepfake Video Detection Based on MesoNet with Preprocessing Module

With the development of computer hardware and deep learning, face manipulation
videos represented by Deepfake have been widely spread on social media. From the perspective of symmetry, many forensics methods have been raised, while most detection performance might drop under compression attacks. To solve this robustness issue, this Project proposes a Deepfake video detection method based on MesoNet with preprocessing module. First, the preprocessing module is established to preprocess the cropped face images, which increases the discrimination among multi-color channels. Next, the preprocessed images are fed into the classic MesoNet. The detection performance of proposed method is verified on  datasets; and can  reach 0.943 on Celeb-DF. More importantly, even in the case of heavy compression, the detection rate can still be more than 88%.

# Step 0: Install Environment
"""

!nvidia-smi

!pip install tensorflow
!pip install mtcnn
!pip install opencv-python-headless
!pip install opencv-python-headless mtcnn tensorflow keras

"""## Step 1: Download Data

This Data is from https://paperswithcode.com/dataset/celeb-df

The Name of the Dataset is "Celeb-DF"
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

# Update the file path to match your directory structure in Google Drive
metadata_path = '/content/drive/MyDrive/Celeb-DF/List_of_testing_videos.txt'

# Load the metadata
metadata_df = pd.read_csv(metadata_path)
print(metadata_df.head())

print(metadata_df.info())
print(metadata_df.describe())

"""### Step 2: Preprocessing

#Frame Extraction
"""

import cv2
import os

def extract_frames(video_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    cap = cv2.VideoCapture(video_path)
    count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        cv2.imwrite(os.path.join(output_folder, f"frame{count:04d}.jpg"), frame)
        count += 1
    cap.release()

"""# Face Detection and Alignment"""

from mtcnn import MTCNN
import cv2

def detect_and_align_faces(frame_folder, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    detector = MTCNN()
    for img_name in os.listdir(frame_folder):
        img_path = os.path.join(frame_folder, img_name)
        img = cv2.imread(img_path)
        faces = detector.detect_faces(img)
        for i, face in enumerate(faces):
            x, y, width, height = face['box']
            cropped_face = img[y:y+height, x:x+width]
            aligned_face = cv2.resize(cropped_face, (224, 224))
            cv2.imwrite(os.path.join(output_folder, f"{img_name[:-4]}_face{i}.jpg"), aligned_face)

"""# Normalization"""

import cv2
import numpy as np

def normalize_images(face_folder, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    for img_name in os.listdir(face_folder):
        img_path = os.path.join(face_folder, img_name)
        img = cv2.imread(img_path)
        img = img / 255.0  # Normalizing to [0, 1]
        cv2.imwrite(os.path.join(output_folder, img_name), img * 255)  # Converting back to original range

"""# Data Augmentation"""

import cv2
import os
from albumentations import (Compose, RandomCrop, HorizontalFlip, RandomBrightnessContrast)

def augment_images(face_folder, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    augmentations = Compose([
        RandomCrop(width=200, height=200),
        HorizontalFlip(p=0.5),
        RandomBrightnessContrast(p=0.2)
    ])
    for img_name in os.listdir(face_folder):
        img_path = os.path.join(face_folder, img_name)
        img = cv2.imread(img_path)
        augmented = augmentations(image=img)['image']
        cv2.imwrite(os.path.join(output_folder, f"aug_{img_name}"), augmented)

"""# Temporal Consistency Analysis

"""

import cv2
import numpy as np

def analyze_temporal_consistency(frame_folder):
    frames = []
    for img_name in sorted(os.listdir(frame_folder)):
        img_path = os.path.join(frame_folder, img_name)
        img = cv2.imread(img_path)
        frames.append(img)
    # Simple temporal analysis by checking pixel differences between consecutive frames
    for i in range(1, len(frames)):
        diff = cv2.absdiff(frames[i], frames[i-1])
        mean_diff = np.mean(diff)
        print(f"Frame {i-1} to Frame {i} difference: {mean_diff}")

"""# Feature Extraction"""

import cv2
import numpy as np
from sklearn.feature_extraction import image

def extract_features(face_folder):
    features = []
    for img_name in os.listdir(face_folder):
        img_path = os.path.join(face_folder, img_name)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        # Example feature extraction: Histogram of Oriented Gradients (HOG)
        hog = cv2.HOGDescriptor()
        hog_features = hog.compute(img)
        features.append(hog_features)
    return np.array(features)

"""# Noise Reduction"""

import cv2
import os

def reduce_noise(face_folder, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    for img_name in os.listdir(face_folder):
        img_path = os.path.join(face_folder, img_name)
        img = cv2.imread(img_path)
        denoised_img = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)
        cv2.imwrite(os.path.join(output_folder, img_name), denoised_img)

"""## Video Display"""

import cv2
from google.colab.patches import cv2_imshow

# Path to the video file
video_path = '/content/drive/MyDrive/Celeb-DF/Celeb-synthesis/id13_id10_0000.mp4'

# Open the video file
cap = cv2.VideoCapture(video_path)

# Check if the video opened successfully
if not cap.isOpened():
    print("Error: Could not open video.")
else:
    # Read and display frames from the video
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        cv2_imshow(frame)  # Display the frame
        # Wait for a short period to simulate video playback
        if cv2.waitKey(25) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

"""## Verification"""

import os

# Update paths to directories containing videos
real_videos_dir = '/content/drive/MyDrive/Celeb-DF/Celeb-real'
fake_videos_dir = '/content/drive/MyDrive/Celeb-DF/Celeb-synthesis'

# Verify the contents of the directories
print("Real videos directory contents:")
print(os.listdir(real_videos_dir))

print("Fake videos directory contents:")
print(os.listdir(fake_videos_dir))

"""# Training (using the **Mesonet Architecture**)"""

import numpy as np
import cv2
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from sklearn.model_selection import train_test_split

# Function to extract frames and preprocess
def extract_and_preprocess_frames(video_path, label, frame_count=10, img_size=(128, 128)):
    cap = cv2.VideoCapture(video_path)
    frames = []
    labels = []
    count = 0
    while cap.isOpened() and count < frame_count:
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, img_size)
        frame = frame.astype('float32') / 255.0
        frames.append(frame)
        labels.append(label)
        count += 1
    cap.release()
    return np.array(frames), np.array(labels)

# Load and preprocess dataset
def load_dataset(real_dir, fake_dir, frame_count=10):
    X, y = [], []

    # Process real videos
    for video in os.listdir(real_dir):
        video_path = os.path.join(real_dir, video)
        if os.path.isfile(video_path):
            frames, labels = extract_and_preprocess_frames(video_path, 0, frame_count)
            X.append(frames)
            y.append(labels)

    # Process fake videos
    for video in os.listdir(fake_dir):
        video_path = os.path.join(fake_dir, video)
        if os.path.isfile(video_path):
            frames, labels = extract_and_preprocess_frames(video_path, 1, frame_count)
            X.append(frames)
            y.append(labels)

    X = np.concatenate(X)
    y = np.concatenate(y)
    return X, y

# Define the build_mesonet function
def build_mesonet():
    model = Sequential()
    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))
    model.add(MaxPooling2D((2, 2)))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    return model

# Directories for real and fake videos
real_videos_dir = '/content/drive/MyDrive/Celeb-DF/Celeb-real'
fake_videos_dir = '/content/drive/MyDrive/Celeb-DF/Celeb-synthesis'

# Load dataset
X, y = load_dataset(real_videos_dir, fake_videos_dir)

# Split dataset into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Data augmentation
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

val_datagen = ImageDataGenerator()

# Create data generators
train_generator = train_datagen.flow(X_train, y_train, batch_size=32)
val_generator = val_datagen.flow(X_val, y_val, batch_size=32)

# Build the Mesonet model
model = build_mesonet()

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_generator, epochs=20, validation_data=val_generator)

# Evaluate the model
val_loss, val_accuracy = model.evaluate(val_generator)
print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')

# Save the model
model.save('mesonet_deepfake_detector.h5')

"""## Prediction"""

from tensorflow.keras.models import load_model

# Load the trained model
model = load_model('mesonet_deepfake_detector.h5')

# Function to predict if a video is deepfake
def predict_video(video_path, model, frame_count=10, img_size=(128, 128)):
    frames, _ = extract_and_preprocess_frames(video_path, label=None, frame_count=frame_count, img_size=img_size)
    predictions = model.predict(frames)
    avg_prediction = np.mean(predictions)
    return 'Fake' if avg_prediction > 0.5 else 'Real'

# Predict on a new video
new_video_path = '/content/drive/MyDrive/Celeb-DF/Celeb-real/id10_0001.mp4'
prediction = predict_video(new_video_path, model)
print(f'The video is predicted to be: {prediction}')

from tensorflow.keras.models import load_model

# Load the trained model
model = load_model('mesonet_deepfake_detector.h5')

# Function to predict if a video is deepfake
def predict_video(video_path, model, frame_count=10, img_size=(128, 128)):
    frames, _ = extract_and_preprocess_frames(video_path, label=None, frame_count=frame_count, img_size=img_size)
    predictions = model.predict(frames)
    avg_prediction = np.mean(predictions)
    return 'Fake' if avg_prediction > 0.5 else 'Real'

# Predict on a new video
new_video_path = '/content/drive/MyDrive/Celeb-DF/Celeb-real/id0_0001.mp4'
prediction = predict_video(new_video_path, model)
print(f'The video is predicted to be: {prediction}')